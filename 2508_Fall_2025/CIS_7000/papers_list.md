- 2025-9-10	
  - AR1	
    - Conditional Image Generation with PixelCNN Decoders (van den Oord et al., 2016),
    - Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Gu & Dao, 2023)
    - Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation (Sun et al., 2024),
    - Learning to (Learn at Test Time): RNNs with Expressive Hidden States (Sun et al., 2024), 
    - Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction (Tian et al., 2024)

- 2025-9-15	
  - AR2	
    - Neural Discrete Representation Learning (van den Oord et al., 2017),
    - Taming Transformers for High-Resolution Image Synthesis (Esser et al., 2021),
    - An Image is Worth 32 Tokens for Reconstruction and Generation (Yu et al., 2024).
    - Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models (Yao et al., 2025)
  
- 2025-9-17	
  - NF	
    - Density Estimation Using Real NVP (Dinh et al., 2017),
    - Glow: Generative Flow with Invertible 1×1 Convolutions (Kingma & Dhariwal, 2018),
    - Flow++: Improving Flow-Based Generative Models with Variational Dequantization (Ho et al., 2019),
    - STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis (Gu et al., 2025)

- 2025-9-22	
  - VAE	
    - Auto-Encoding Variational Bayes (Kingma & Welling, 2014),
    - Very Deep VAEs: A Neural Architecture for Probabilistic Autoregressive Modeling (Child, 2021),
    - NVAE: A Deep Hierarchical Variational Autoencoder (Vahdat & Kautz, 2020)
    - beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework (Higgins et al., 2017)

- 2025-9-24	
  - EBM	
    - Your Classifier Is Secretly an Energy Based Model (Grathwohl et al., 2020),
    - Implicit Generation and Generalization in Energy-Based Models (Du & Mordatch, 2020),
    - Energy-Based Transformers are Scalable Learners and Thinkers (Gladstone et al., 2025)
    - Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and - Probabilistic Interpretations (Xu et al., 2024)

- 2025-9-29	
  - Diffusion1	
    - Denoising Diffusion Probabilistic Models (Ho et al., 2020),
    - Denoising Diffusion Implicit Models (Song et al., 2021),
    - Elucidating the Design Space of Diffusion-Based Generative Models (Karras et al., 2022),
    - High-Resolution Image Synthesis with Latent Diffusion Models (Rombach et al., 2022),
    - Scalable Diffusion Models with Transformers (Peebles & Xie, 2023)

- 2025-10-1
  - Diffusion2	
    - Neural Ordinary Differential Equations (Chen et al., 2018),
    - Free-Form Jacobian of Reversible Dynamics for Scalable Variational Inference (Grathwohl et al., 2019),
    - Diffusion Schrödinger Bridge with Applications to Score-Based Generative Modeling  (De Bortoli et al., 2021)
    - Flow Matching for Generative Modeling (Lipman et al., 2023),
    - Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow (Liu et al., - 2022)

- 2025-10-6	
  - Diffusion3	
    - DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Models (Lu et al., 2022),
    - Consistency Models (Song et al., 2023),
    - Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion (Kim et - al., 2023),
    - Mean Flows for One-step Generative Modeling (Geng et al., 2025),
    - How to build a consistency model: Learning flow maps via self-distillation (Boffi et al., 2025)

- 2025-10-8	
  - AR+Diffusion	
    - Autoregressive Image Generation without Vector Quantization (Li et al., 2024),
    - DART: Denoising Autoregressive Transformer for Scalable Text-to-Image Generation (Gu et al., 2024),
    - Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion (Chen et al., 2024)

- 2025-10-13	
  - NAR	
    - Structured Denoising Diffusion Models in Discrete State-Spaces (Austin et al., 2021),
    - Diffusion-LM Improves Controllable Text Generation (Li et al., 2022),
    - MaskGIT: Masked Generative Image Transformer (Chang et al., 2022)

- 2025-10-15	
  - T2I T2V	
    - Scaling Rectified Flow Transformers for High-Resolution Image Synthesis (Esser et al., 2024),
    - Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (Saharia et al., 2022),
    - Wan: Open and Advanced Large-Scale Video Generative Models (Wan et al., 2025)

- 2025-10-27	
  - Controllable	
    - Adding Conditional Control to Text-to-Image Diffusion Models (Zhang & Agrawala, 2023),
    - Classifier-Free Diffusion Guidance (Ho & Salimans, 2022)
    - Prompt-to-Prompt Image Editing with Cross-Attention Control (Hertz et al., 2022),
    - T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion - Models (Mou et al., 2023)

- 2025-10-29	
  - 3D/4D	
    - DreamFusion: Text-to-3D using 2D Diffusion (Poole et al., 2022),
    - Structured 3D Latents for Scalable and Versatile 3D Generation (Xiang et al., 2025),
    - Wonder3D: Single Image to 3D using Cross-Domain Diffusion (Long et al., 2023)
    - CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models (Wu et al., 2024)

- 2025-11-3	
  - Audio/Speech	
    - WaveNet: A Generative Model for Raw Audio (van den Oord et al., 2016),
    - Tacotron: Towards End-to-End Speech Synthesis (Wang et al., 2017),
    - DiffWave: A Versatile Diffusion Model for Audio Synthesis (Kong et al., 2020),
    - Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers (Wang et al., 2023)

- 2025-11-5	
  - LLM1	
    - Training Compute-Optimal Large Language Models (Hoffmann et al., 2022),
    - LLaMA: Open and Efficient Foundation Language Models (Touvron et al., 2023),
    - Mistral 7B (Jiang et al., 2023),
    - DeepSeek-V3 Technical Report (DeepSeek- AI et al., 2024)

- 2025-11-10	
  - LLM2	
    - Training language models to follow instructions with human feedback (Ouyang et al., 2022)
    - Direct Preference Optimization: Your Language Model is Secretly a Reward Model (Rafailov et al., 2023),
    - DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models (Shao et al., 2024),
    - Demystifying Long Chain-of-Thought Reasoning in LLMs (Yeo et al., 2025)

- 2025-11-12	
  - LLM3	
    - OpenAI o1 System Card (OpenAI team et al., 2024),
    - DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning (DeepSeek- AI - et al., 2025),
    - Kimi k1.5: Scaling Reinforcement Learning with LLMs (Kimi Team et al., 2025)

- 2025-11-17	
  - MMLM	
    - BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language - Models (Li et al., 2023),
    - Visual Instruction Tuning (Liu et al., 2023),
    - Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond (Bai et al., 2023),
    - OLMo: Accelerating the Science of Language Models (Groeneveld et al., 2024)

- 2025-11-19	
  - Unified Models	
    - Emerging Properties in Unified Multimodal Pretraining (Deng et al., 2025),
    - Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model (Zhou et al., 2024),
    - Emu3: Next-Token Prediction is All You Need (Wang et al., 2024)
    - Transfer between Modalities with MetaQueries (Pan et al., 2025)

- 2025-11-24	
  - World Models	
    - Mastering Atari with Discrete World Models (Hafner et al., 2020),
    - Genie: Generative Interactive Environments (Bruce et al., 2024),
    - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model (Schrittwieser et al., - 2019),
    - V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning (Assran et al., 2025)

- 2025-12-1	
  - Robotics	
    - Diffusion Policy: Visuomotor Policy Learning via Action Diffusion (Chi et al., 2024),
    - RT-1: Robotics Transformer for Real-World Control at Scale (Brohan et al., 2022),
    - Do As I Can, Not As I Say: Grounding Language in Robotic Affordances (Ahn et al., 2022)
  
- 2025-12-3	
  - AI4S	
    - DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking (Corso et al., 2022),
    - Language models of protein sequences at the scale of evolution enable accurate structure - prediction (Lin et al., 2022),
    - Reanimating Images using Neural Representations of Dynamic Stimuli (Yeung et al., 2025)
    - AstroPT: Scaling Large Observation Models for Astronomy (Smith et al., 2024),
    - Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity (Chen et al., 2023)