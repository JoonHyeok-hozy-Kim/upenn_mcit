[Back to Main](../main.md)

# 2. Gaussian Process

### Concept) Gaussian Process
- Def.)
  - An extension of the familiar multivariate normal distribution suitable for modeling functions on infinite domains
  - Let
    - $`f:\mathcal{X}\rightarrow\mathbb{R}`$ : an objective function of interest over an arbitrary infinite domain $`\mathcal{X}`$
  - Then a Gaussian Process on $`f`$ can be defined as
    - $`p(f) = \mathcal{GP}(f;\mu,K)`$
      - where
        - $`\mu:\mathcal{X}\rightarrow\mathbb{R}`$ is a mean function
          - i.e.) $`\mu(x) = \mathbb{E}[\phi\mid x],\;\forall x\in\mathcal{X}`$
        - $`K:\mathcal{X}\times\mathcal{X}\rightarrow\mathbb{R}`$ is a covariance(kernel) function
          - i.e.) $`K(x,x') = \text{cov}[\phi,\phi'\mid x,x'],\; \forall x,x'\in\mathcal{X}`$

#### e.g.) Finite-Dimensional Marginal Distribution
  - Let
    - $`\mathbf{x}=\begin{bmatrix}x_1,\cdots,x_n\end{bmatrix}\subset\mathcal{X}`$
    - $`\boldsymbol{\phi} = f(\mathbf{x})\subset\mathcal{Y}`$
  - Then the distribution of $`\boldsymbol{\phi}`$ can be denoted using GP as
    - $`p(\boldsymbol{\phi}\mid \mathbf{x}) = \mathcal{N}(\boldsymbol{\phi};\boldsymbol{\mu},\Sigma)`$
      - where
        - $`\boldsymbol{\mu} = \mathbb{E}[\boldsymbol{\phi}\mid\mathbf{x}] = \mu(\mathbf{x})`$
        - $`\Sigma = \text{cov}[\boldsymbol{\phi}\mid\mathbf{x}] = K(\mathbf{x,x})`$
          - where $`\Sigma_{ij} = K(x_i,x_j)`$ i.e. the Gram matrix of $`\mathbf{x}`$

#### Concept) Jointly Gaussian Observation
- Situation)
  - Suppose we observed some points $`\mathcal{D} = (\mathbf{x}, \mathbf{y})`$.
  - How do we condition a GP on theses observations?
- Settings)
  - $`p(f) = \mathcal{GP}(f;\mu,K)`$ : a GP
  - $`\mathbf{y}`$ : the observed values s.t. $`p(\mathbf{y})\sim\mathcal{N}(\mathbf{y};\mathbf{m,C})`$
  - $`\kappa(x) = \text{cov}[\mathbf{y},\phi\mid x]`$ : the cross covariance function between $`f`$ and $`\mathbf{y}`$
- Then the joint Gaussian distribution of $`f`$ and $`\mathbf{y}`$ can be denoted as
  - $`p(f,\mathbf{y}) = \mathcal{GP}\left(\begin{bmatrix} f\\ \mathbf{y} \end{bmatrix}; \begin{bmatrix} \mu\\\mathbf{m} \end{bmatrix}, \begin{bmatrix} K&\kappa^\top \\ \kappa&\mathbf{C} \end{bmatrix}\right)`$
- Using the joint distribution above, we may derive the GP posterior on $`f`$ as
  - Putting $`\mathcal{D}=\mathbf{y}`$ we have
    - $`p(f\mid\mathcal{D}) = \mathcal{GP(f;\mu_\mathcal{D},K_\mathcal{D})}`$
      - where
        - $`\mu_\mathcal{D}(x) = \mu(x) + \kappa(x)^\top \mathbf{C}^{-1} (\mathbf{y-m})`$
        - $`K_\mathcal{D}(x,x') = K(x,x')-\kappa(x)^\top \mathbf{C}^{-1}\kappa(x')`$

<br>

### Concept) 

<br>

### Concept) 















<br><br>

[Back to Main](../main.md)