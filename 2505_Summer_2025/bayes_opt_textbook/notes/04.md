[Back to Main](../main.md)

# 4. Model Assessment, Selection, and Averaging

### Concept) Model Assessment
- Def.)
  - Determining which models are the most compatible with the data and thereby establish preferences over possible choices.
- Settings)
  - $`\mathcal{D} = (\mathbf{x,y})`$ : a set of observations
  - $`f`$ : the latent function
    - Desc.)
      - The hidden function that determines the real world.
      - What we want to figure out!
  - $`p(\mathbf{y}\mid\mathbf{x})`$ : a model
    - Desc.)
      - a prior probability distribution over the measured values $`\mathbf{y}`$ that would result from observing at a set of locations $`\mathbf{x}`$.
    - How to specify a model)   
      - $`\left[ p(f), p(y\mid x,\phi) \right]`$ : link prior $`p(f)`$ and observation $`p(y\mid x,\phi)`$
        - Desc.)
          1. $`p(f)`$ : A prior process on a latent function $`f`$
             - Why doing this?)
               - Since we don't know what $`f`$ is, we set our prior of $`p(f)`$
          2. $`p(y\mid x,\phi)`$ : An observation model that contains noise 
             - where $`\phi = f(x)`$ : the latent function value with noise
      - How to link them)
        - $`\displaystyle p(\mathbf{y}\mid\mathbf{x}) = \int p(\mathbf{y}\mid\mathbf{x}, \boldsymbol{\phi}) p(\boldsymbol{\phi}\mid\mathbf{x}) d\boldsymbol{\phi}`$
          - i.e.) Marginalize on $`\boldsymbol{\phi}`$ to drop the noise!
  - $`\mathcal{M} = \left\{ \left[ p(f\mid\boldsymbol{\theta}), p(y\mid x,\phi,\boldsymbol{\theta}) \right] \mid \boldsymbol{\theta}\in\boldsymbol{\Theta} \right\}`$
    - where
      - $`\boldsymbol{\theta}`$ : hyperparameter 
        - i.e.) a vector of any necessary parameters 
        - $`\boldsymbol{\Theta}`$ : the joint range of $`\boldsymbol{\theta}`$
      - $`p(f\mid\boldsymbol{\theta}) = \mathcal{GP}(f;\mu(x;\boldsymbol{\theta}), K(x,x';\boldsymbol{\theta}))`$ : the prior
      - $`p(y\mid x,\phi,\boldsymbol{\theta})`$ : the observed model
- e.g.)
  - Domain $`\mathcal{X} = [a,b]`$
  - Initial beliefs...
    - the objective will exhibit stationary behavior with a constant trend near zero
    - our observations will be corrupted by additive noise
  - Setting the observation model)
    - $`p(y\mid\phi,\sigma_n) = \mathcal{N}(y;\phi,\sigma_n^2)`$
      - Desc.)
        - homoskedastic additive Gaussian noise
  - Setting the prior)
    - Mean Function)
      - $`\mu(x;c) \equiv c`$ where $`p(c) = \mathcal{N}(c; 0,b^2)`$
        - Desc.)
          - A constant mean function with zero-mean normal prior on unknown constant $`c`$.
    - Covariance Function)
      - $`K(x,x';\lambda,\ell) = \lambda^2 K_{M_{5/2}}(d/\ell)`$
        - Desc.)
          - the [Matérn](./03.md#concept-the-matérn-family-covariance-functions) covariance function with $`\nu = 5/2`$
          - $`\lambda`$ : the [output scale](./03.md#concept-output-space-scaling)
          - $`\ell`$ : the unknown [length scale](./03.md#concept-design-space-domain-transformation)
  - By marginalizing the unknown constant mean $`c`$ under its assumed prior, we have the zero mean function and the additive contribution to the covariance function of
    - $`\mu(x) \equiv 0`$
    - $`K(x,x';\lambda,\ell) = b^2 + \lambda^2 K_{M_{5/2}}(d/\ell)`$
  - Now we have hyperparameters $`\theta = [\sigma_n, \lambda, \ell]^\top`$

<br>

### Concept) 

<br>

### Concept) 






<br><br>

[Back to Main](../main.md)