# 🚀 CUDA 개념 정리 노트

---

## 1. CUDA의 실행 계층 구조 (Hierarchy)

CUDA는 병렬 작업을 다음과 같은 계층 구조로 조직합니다:

Grid   
└── Block   
└── Thread   
(실행 단위: Warp = 32 threads)


### 🔹 Thread
- GPU에서 연산을 수행하는 **가장 작은 실행 단위**
- 각 thread는:
  - 고유한 `threadIdx` 보유
  - **로컬 메모리(레지스터)** 를 사용
  - 독립적인 흐름으로 실행

### 🔹 Block (Thread Block)
- 여러 thread의 묶음
- block마다:
  - 고유한 `blockIdx`
  - block 내 thread 수: `blockDim`
- 특징:
  - **공유 메모리(shared memory)** 를 이용해 block 내 thread 간 협업 가능
  - block 내부는 `__syncthreads()`로 동기화 가능
  - 보통 block 크기는 `(16, 16)` 또는 `(32, 32)` 형태

### 🔹 Grid
- 여러 block으로 구성된 상위 구조
- grid 내 block 수: `gridDim`
- 전체 grid가 하나의 kernel을 실행
- grid 내 block 간에는 **직접 통신 불가**

### 🔹 Warp
- 하드웨어 스케줄링 단위
- 32개의 thread가 **SIMT(Single Instruction, Multiple Thread)** 방식으로 함께 실행
- warp 단위로 instruction이 스케줄러에 의해 분배됨
- 한 SM(Streaming Multiprocessor)당 보통 여러 warp가 병렬 실행

---

### ✅ 예제: 2x2 행렬 덧셈

A + B = C

Thread 배치:

Block (0,0)   
┌────────────┐   
│ T(0,0) T(0,1) │ → C[0][0], C[0][1]   
│ T(1,0) T(1,1) │ → C[1][0], C[1][1]   
└────────────┘   


각 thread는 다음과 같은 코드로 자신의 작업을 수행:

```cpp
int row = threadIdx.y;
int col = threadIdx.x;
C[row][col] = A[row][col] + B[row][col];

int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;
C[row][col] = A[row][col] + B[row][col];
```

## 2. GPU 병렬 실행 & 비동기성

### 🔹 병렬성
- 여러 thread가 각기 다른 데이터 조각을 동시에 처리
- 예: 행렬 덧셈에서 각 thread가 하나의 원소 합산

### 🔹 비동기성
- 커널 호출 (`kernel<<<...>>>`) 은 GPU에게 **작업만 지시하고 CPU는 기다리지 않고 다음 줄로 넘어감**
- GPU 작업이 끝났는지는 **동기화(sync)** 를 통해 확인

### 🔹 동기화 방법

| 함수 | 설명 |
|------|------|
| `cudaDeviceSynchronize()` | 전체 GPU 작업이 끝날 때까지 기다림 |
| `cudaStreamSynchronize(stream)` | 특정 stream의 작업만 대기 |
| `cudaEventSynchronize(event)` | 특정 event 시점까지 대기 |
| `cudaMemcpy()` | 암묵적 동기화 포함 (GPU 작업이 끝난 후 복사 진행됨) |

> 비유: `cudaDeviceSynchronize()`는 `wait()`, `cudaStreamSynchronize()`는 `waitpid(pid)`에 해당

---

## 3. 메모리 관리

### 🔹 GPU 메모리 함수

| 함수 | 설명 |
|------|------|
| `cudaMalloc(&ptr, size)` | GPU 전역 메모리 할당 |
| `cudaMemcpy(dst, src, size, direction)` | CPU ↔ GPU 간 복사 |
| `cudaFree(ptr)` | GPU 메모리 해제 |

### 🔹 메모리 종류

| 종류 | 범위 | 특징 |
|------|------|-------|
| 로컬 메모리 | thread | 레지스터 or stack |
| 공유 메모리 | block | 빠른 속도, thread 간 협업 |
| 전역 메모리 | grid | CPU ↔ GPU 간 데이터 공유 |
| 상수 메모리 | 전체 | 읽기 전용, broadcast 최적화 |

### 🔹 C++식 RAII로 감싸기

```cpp
class CudaMemory {
    float* ptr;
public:
    CudaMemory(size_t size) { cudaMalloc(&ptr, size); }
    ~CudaMemory() { cudaFree(ptr); }
    float* get() const { return ptr; }
};
```

## 4. PTX와 컴파일 구조

### 🔹 PTX란?
- NVIDIA의 **중간 언어(IR)** (Parallel Thread Execution)
- CUDA 코드(`__global__`, `__device__`)는 PTX로 먼저 컴파일됨
- PTX는 실행 시점에 GPU 기종에 맞게 JIT 컴파일됨

### 🔹 컴파일 흐름
.cu (CUDA 소스)   
↓   
nvcc 컴파일   
↓   
├─ Host 코드 → x86 바이너리   
└─ Device 코드 → PTX   
↓ (JIT)   
GPU 기계어(SASS)   



---

## 5. CUDA 플랫폼 종속성과 대안

| 항목 | NVIDIA (CUDA) | AMD (HIP/ROCm) | Intel (SYCL/oneAPI) |
|------|----------------|----------------|----------------------|
| 중간 언어 | PTX | LLVM IR / GCN | LLVM IR |
| API | CUDA | HIP / OpenCL | SYCL / DPC++ |
| 컴파일러 | `nvcc` | `hipcc` / `clang` | `dpcpp`, `icx` |
| GPU 독립성 | ❌ NVIDIA 전용 | ✅ 일부 지원 | ✅ 표준 기반 |
| 생태계 | 성숙, 강력 | 성장 중 | 초기 단계 |

> PTX는 NVIDIA 전용이므로 AMD/Intel에서는 실행 불가  
> AMD는 `hipify` 도구로 CUDA 코드를 HIP으로 변환 가능
