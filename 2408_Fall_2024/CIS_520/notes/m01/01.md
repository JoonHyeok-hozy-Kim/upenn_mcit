# 1. What is Machine Learning
#### Concept) Model
- Desc.)
  - A predictive (or decision-making) tool
  - The performance of the model is evaluated based on some underlying performance measure or criterion.

#### Concept) Model Training
- Def.)
  - The learning procedure that produces the [model](#concept-model).
- How?)
  - Given the **data**, the **learning algorithm** takes the training data as input, and produces a [model](#concept-model) as output.
- Properties that Specify a Model)
  - What data are used?
  - What learning algorithm is used?
  - How do we configure the learning algorithm?
    - by setting hyperparameters
  - How do we evaluate the performance of a model?

<br>

## 1.1 Machine Learning Paradigms

|Learning Algorithm|Desc.|Goal|e.g.|
|:-:|:-|:-|:-|
|Supervised Learning|Training data consists of **instance** and **label** pairs. |Predict well on future instances.|regression, classification|
|Unsupervised Learning|Training data consists of **only instances**, **no labels**.|Learn some patterns and structures in the data |clustering, anomaly detection|
|Reinforcement learning|Unlike the above methods, no data is directly given to the learning algorithm (or agent). <br> There is a set of states that an agent can be in, a set of actions that can be taken in each state which transition the agent to another state, and a ‘reward’ signal based on the state it transitions into.| Learn a model (or policy), that determines  which action the agent should take in each state, such that it maximizes the overall reward that is collected by following the policy from a fixed start state.||

<br><br>

# 2. Supervised Learning
### Model) Supervised Learning
- Settings)
  - $`\mathcal{D} = ((x_1, y_1), \cdots, (x_n, y_n))`$ : $`n`$ labeled examples
    - where 
      - for each labeled example $`(x_i, y_i)`$
        - $`x_i`$ : the features
        - $`y_i`$ : the label
  - $`\mathcal{X}`$ : the feature space
    - $`x_i \in \mathcal{X}`$
  - $`\mathcal{Y}`$ : the label space
    - $`y_i \in \mathcal{Y}`$
  - $`\mathbf{X}\in \mathbb{R}^{n\times d}`$ : the feature matrix with $`d`$ dimension
  - $`\mathbf{y}\in \mathcal{Y}^n`$ : the label vector
- Model)
  - Given an input $`\mathbf{x}\in\mathcal{X}`$
  - learn a predictor $`h : \mathcal{X}\rightarrow\mathcal{Y}`$
  - make a prediction $`\hat{y} = h(\mathbf{x})`$
    - with the goal that $`\hat{y}\approx y`$

### Types) Supervised Learning
|Model|Desc.|
|:-:|:-|
|Binary Classification|- $`\mathcal{Y} = \{-1, 1\}`$|
|Regression|- $`\mathcal{Y} \subseteq \mathbb{R}`$|
|Multi-Class Classification|- e.g.) $`\mathcal{Y} = \{1,2,3,4\}`$|

<br><br>

# 3. Training Error
### Concept) Training Error
- Objective)
  - Find a way to evaluate how the model $`h(\cdot)`$ performs on data in **training set**.
- e.g.)
  - Binary Classification
    - $`\displaystyle \hat{R}_{0/1}(h) = \frac{1}{n} \sum_{i=1}^n \ell_{0/1}(h(\mathbf{x}_i, y_i))`$ : the training error of a binary classifier $`h`$
      - where $`\ell_{0/1}(h(\hat{y}, y)) = \begin{cases} 0 & \text{if } \hat{y} = y \\ 1 & \text{otherwise} \end{cases}`$
  - Regression : Mean Squared Training Error
    - $`\displaystyle \hat{R}_{sq}(h) = \frac{1}{n}\sum_{i=1}^n \ell_{sq}(h(\mathbf{x}_i, y_i))`$
      - where $`\ell_{sq}(\hat{y}, y) = (\hat{y}-y)^2`$

<br>

### Concept) Empirical Risk Minimization
- Desc.)
  - A general strategy for learning algorithms is to minimize the training error.
    - i.e.) $`\displaystyle \min_{h\in\mathcal{H}} \hat{R}_{sq}(h)`$

<br><br>

# 4. Generalization
### Concept) Generalization
- Desc.)
  - In order for any [model](#concept-model) to be useful, it will need to **generalize** beyond training data.
    - i.e.) Achieve accurate predictions on data outside of the training data

<br>

#### E.g.) Bad Generalization Model
- Model)
  - $`h_{bad}(\mathbf{x}) = \begin{cases} y_i & \exists x_i \in \mathcal{D} \text{ s.t. } \mathbf{x} = \mathbf{x}_i \\ 1 & \text{otherwise} \end{cases}`$
- Desc.)
  - Zero training error!
  - Predict 1 for any input ont in the training data!
- Sol.)
  - Carefully choose the test set data.
    - How?) [the i.i.d. assumption](#concept-true-risk-and-training-error-under-iid).

<br>

### Concept) True Risk and Training Error under i.i.d.
- Desc.)
  - Assume that the data is generated independently and identically from some **underlying unknown distribution** $`\mathcal{P}`$.
    - i.e.) $`(\mathbf{x}, y) \stackrel{\text{i.i.d}}{\sim} \mathcal{P}`$
  - Then, we can define the **risk** of a predictor $`h`$ on unseen examples as follows:
    - $`\underbrace{R(h)}_{\text{True Risk}} = \mathbb{E}_{(\mathbf{x}, y)\sim \mathcal{P}} [\ell(h(\mathbf{x}), y)]`$
  - Under this assumption, the **training error** is a finite sample (monte carlo) approximation of the **true risk**.
    - Thus, we often call the training error, the **empirical risk**.

### Concept) Generalization Gap
- Def.)
  - $`\underbrace{R(h)}_{\text{True Risk}} = \underbrace{(R(h)-\hat{R}(h))}_{\text{Generalization Gap}} + \underbrace{\hat{R}(h)}_{\text{Empirical Risk}}`$
- How to Measure this?)
  - Divide the data $`\mathcal{D}`$ into a training and test set.
    - 80 : 20 is common.

<br>

### Concept) Bayes Optimal Classifier and Bayes Error
- Settings)
  - Binary classification problem.
    - $`y\in \{+1, -1\}`$ : the label
    - $`h(\mathbf{x}) \in \{+1, -1\}`$ : the prediction of our model with data $`\mathbf{x}`$
    - $`\eta(\mathbf{x})`$ : the conditional probability of the label $`+1`$ given $`\mathbf{x}`$
      - i.e.) $`\eta(\mathbf{x}) = Pr(y=+1|\mathbf{x})`$
    - $`\mathbf{1}(S) = \begin{cases} 1 & \text{if } S \text{ is true} \\ 0 & \text{otherwise.} \end{cases}`$
- Derivation)   
  - Then the true risk can be denoted as follows:   
    $`\begin{aligned}
        R(h) &= \mathbb{E}_{(\mathbf{x}, y)\sim\mathcal{P}} [\ell_{0/1}(h(\mathbf{x}), y)] \\
        &= \mathbb{E}_{\mathbf{x}} \left[ \mathbb{E}_{y|\mathbf{x}} [\ell_{0/1}(h(\mathbf{x}), y)] \right] & \because p(x,y) = p(y|x)p(x) \\
        &= \mathbb{E}_{\mathbf{x}} \left[ Pr(y=+1|\mathbf{x}) \mathbf{1}(h(\mathbf{x}=-1)) + Pr(y=-1|\mathbf{x}) \mathbf{1}(h(\mathbf{x}=+1))\right] \\
        &= \mathbb{E}_{\mathbf{x}} \left[ \eta(\mathbf{x}) \mathbf{1}(h(\mathbf{x}=-1)) + (1-\eta(\mathbf{x})) \mathbf{1}(h(\mathbf{x}=+1)) \right]
    \end{aligned}`$
    - Desc.)
      - The risk happens when...
        - $`(y=+1) \wedge (h(\mathbf{x}) = -1)`$ with the probability $`\eta(\mathbf{x})`$.
        - $`(y=-1) \wedge (h(\mathbf{x}) = +1)`$ with the probability $`1-\eta(\mathbf{x})`$.
  - Now we want to derive the optimal classifier $`h^*(\mathbf{x})`$.
    - Then depending on the value of $`\eta(\mathbf{x})`$,  
      - $`h^*(\mathbf{x}) = \begin{cases} 1 & \text{if } \eta(\mathbf{x}) \gt 1- \eta(\mathbf{x}) \Leftrightarrow \eta(\mathbf{x}) \gt 0.5 \\ -1 & \text{otherwise.} \end{cases}`$
        - Why?)
          - We should choose $`h`$ that minimizes $`R(h)`$.
          - If $`\eta(\mathbf{x}) \gt 0.5`$, we can reduce $`R(h)`$ by predicting $`h(\mathbf{x}) = 1 \Rightarrow R(h) = 1-\eta(\mathbf{x})`$.
    - This optimal classifier is called the Bayes optimal classifier for $`\mathcal{P}`$.
    - Formally,
      - $`\begin{aligned} R^* = \min_{h:\mathcal{X}\rightarrow \pm 1} R(h) &= \mathbb{E}_\mathbf{x}\left[ \eta(\mathbf{x}) \mathbf{1}(h(\mathbf{x}=-1)) + (1-\eta(\mathbf{x})) \mathbf{1}(h(\mathbf{x}=+1)) \right] \\ &= \mathbb{E}_\mathbf{x}\left[ \min(\eta(\mathbf{x}), 1-\eta(\mathbf{x})) \right] \end{aligned}`$