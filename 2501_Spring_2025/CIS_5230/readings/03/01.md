# Inherent Trade-Offs in the Fair Determination of Risk Scores

- Too many constraints, cannot serve for the fairness


## 1. Brief Overview
- Three Examples)
  1. Criminal justice system (COMPAS)
  2. Internet Advertisement different by Genders
  3. Medical testing and diagnosis playing different role in different groups
- Terms)
  - Positive Instance
    - A group of people that truly possess certain property
  - Negative Instance
    - A group of people that does not possess certain property
- What sorts of **guarantees** should we ask for as protection against potential bias?
  1. Calibration
     - Desc.)
       - Probability distribution derived by the algorithm should correspond with the actual instances.
     - e.g.)
       - If the algorithm identifies a set of people as having a probability $`z`$ of constituting positive instances, then approximately a z fraction of this set should indeed be positive instances
  2. Balance for the positive/negative class
     - Desc.)
       - Balance or positive class
         - the average score received by people constituting positive instances should be the same in each group
  3. Statistical Parity
     - Desc.)
       - the average probability estimate globally over all members of the two groups be equal
- Trade-offs among Guarantees
  - Above conditions are in general incompatible with each other

<br><br>

## 2. Formal Definition of the Problem)
### Concept) Positive (Negative) Class
  - Def)
    - A group of people who constitute [positive (negative) instances](#brief-overview)
  - e.g.)
    - (Positive) : those defendants who will be arrested again within some fixed time window
  - Meaning)
    - Correct answers to the classification problems.


### Concept) Feature Vector $`\sigma`$
  - Desc.)
    - Each person has $`\sigma`$
      - This represents the data we know about them. 
    - $`p_\sigma`$ : the fraction of people with $`\sigma`$ who belong to positive class
      - Variation on $`\sigma`$ among people are invisible to the decision procedure.
      - Thus, people in $`p_\sigma`$ are indistinguishable to the procedure.
      - Our model assumes that $`p_\sigma`$ for each $`\sigma`$ is known.


### Concept) Groups $`t\in\{1,2\}`$
  - For the simplicity, we consider two groups labeled 1 and 2.
    - e.g.)
      - Male / Female
      - Black / White
    - Why introducing this concept?)
      - To look for the possibility of bias between them.
  - Each person belongs to either 1 or 2.
  - For the Group $`t \in \{1,2\}`$
    - $`a_{t\sigma}`$ : the probability that a person of group $`t`$ exhibits $`\sigma`$
      - It contains all the relevant information available to us about the person’s future behavior.
      - This shows the frequency of the feature vectors in each group.
      - Assumption : Once we know $`\sigma`$, we do not get any additional information from knowing their group as well.


### Concept) Risk Assignments
  - Settings)
    - $`b`$ : bin
    - $`v_b`$ : a risk score that labels $`b`$
      - e.g.) Recidivism score 0~1 can be represented as 11 bins with $`v_b \in \{0, 0.1,\cdots,0.9, 1\}`$
  - Goal)
    - Recall that there were group of people sharing $`\sigma`$.
    - We will assign some portion of each group to each bin.
    - The fraction is denoted by $`X_{\sigma b}`$
      - i.e.) A fraction $`X_{\sigma b}`$ of all people with $`\sigma`$ are assigned to $`b`$.
  - Why doing this?)
    - This allows dividing people with $`\sigma`$ across multiple bins
    - Give randomness in assignment


### Concept) Fairness Properties for Risk Assignments
  - (A) Calibration within Groups
     - Desc.)
       - For each group $`t`$, and each bin $`b`$, the expected number of people from $`t`$ in $`b`$ who belongs to the positive class should be $`v_b \cdot \mathbb{E}[\text{num of people from } t \text{ assigned to }b]`$
     - e.g.)
       - Suppose the recidivism score $`v_b = 0.7`$.
       - Then, 0.7 fraction of people from $`t`$ assigned to $`b`$ should recidivate.
     - Interpretation)
       - The scores mean what they claim to mean, even when considered separately in each group.
       - People should be treated by the score $`v_b`$, not the group $`t`$ they came from.
  - (B) Balance for the negative class
     - Desc.)
       - the average score assigned to people of $`t=1`$ who belong to the negative class should be the same as the average score assigned to people of group $`t=2`$
     - Interpretation)
       - If two individuals in different groups exhibit future negative behavior, they should be labeled with same score
       - If violated, the members of the negative class in one group receiving consistently higher scores than the members of the negative class in the other group who belong to the negative class
     - e.g.)
       - Recidivism Example)
         - Black negative class received higher recidivism score compared to white negative class.
  - (C) Balance for the positive class
     - Desc.)
       - the average score assigned to people of $`t=1`$ who belong to the positive class should be the same as the average score assigned to people of group $`t=2`$


### Concept) Trade-off of (A),(B),and (C)
  - COMPAS Case)
    - (A) was satisfied
    - (B), (C) were violated.
  - Internet Advertisement
    - 예를 들어, 남성 사용자는 광고에 대해 전반적으로 높은 클릭률을 보이고, 여성 사용자는 낮은 클릭률을 보인다고 가정합시다. 조건 (A)를 충족시키기 위해 남성 그룹에는 높은 클릭 확률(높은 위험 점수)을, 여성 그룹에는 낮은 클릭 확률(낮은 위험 점수)을 부여한다면, 이는 두 그룹의 “평균 점수”가 다르게 됩니다. 반면, 조건 (C)는 광고를 클릭할 가능성이 높은 남성과 여성 사용자에게 동일한 점수를 주어야 하므로, 만약 여성 그룹의 긍정 클래스 비율이 낮아도 점수를 올려야 하는 상황이 발생할 수 있습니다.

<br><br><br>

## 3. Characterization Theorem
- Two simple cases that (A), (B), and (C) can be simultaneously achieved.
  - Perfect Prediction
    - Desc.)
      - For each $`\sigma`$, we have either $`p_\sigma = 0`$ or $`p_\sigma =1`$.
    - Meaning)
      - We know the class label positive/negative only with $`\sigma`$.
      - In this case, assign 
        - all $`\sigma`$ with $`p_\sigma = 0`$ to a bin $`b`$ with $`v_b=0`$
        - all $`\sigma`$ with $`p_\sigma = 1`$ to a bin $`b`$ with $`v_b=1`$
      - Then, (A-C) can be achieved at the same time.
  - Equal Base Rates
    - Each group has the same fraction of members in the positive class.
      - This is called the base rate of the group w.r.t. the classification problem.
    - In this case, we can set up a single bin $`b`$, with $`v_b = p_\sigma`$ and assign everyone into this single bin.

### Thm 1.1) 
Consider an instance of the problem in which there is a risk assignment satisfying fairness conditions (A), (B), and (C). Then the instance must either allow for perfect prediction (with pσ equal to 0 or 1 for all $`\sigma`$) or have equal base rates.


### Thm 1.2)
There is a continuous function $`f`$, with $`f(x)`$ going to 0 as $`x`$ goes to 0, so that the following
holds. For all $`\epsilon \gt 0`$, and any instance of the problem with a risk assignment satisfying the ε-approximate
versions of fairness conditions (A), (B), and (C), the instance must satisfy either the $`f(\epsilon)`$-approximate
version of perfect prediction or the $`f(\epsilon)`$-approximate version of equal base rates.
- Meaning)
  - For each two conditions in [Thm 1.1](#thm-11)
    - Perfect Prediction
      - If we can loosen the conditions by allowing $`\epsilon \gt 0`$ of errors, we can define $`\epsilon`$-approximate versions of each conditions.
    - Equal Base Rates
      - We may loosen the conditions by allowing the base rates of each group to deviate by $`\delta \gt 0`$.
        - i.e.) $`\vert \text{base rate}_1 - \text{base rate}_2 \vert \le \delta`$
