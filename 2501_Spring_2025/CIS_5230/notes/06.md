[Back to Main](../main.md)

# Ethical Algorithm Design and Generative AI
- Historically...
  - 90s, N-GRAM model

### Concept) Generative AI Concerns
- Bias / Stereotyping
- Privacy / Copyright / IP
- Toxicity
  - Generating offensive concepts
- Hallucination
  - Generating verifiably false
- Plagiarism / Cheating
- Disruption to work / labor / society
- Adversarial Attack
  - e.g.) Adding human unrecognizable but machine recognizable data to generate false inference. (Traffic light - red)
- Security

<br><br>

### Concept) Neural Network Background
- Single Neuron
  - Input : $`x\in\mathbb{R}^d`$
  - Output : $`f(w\cdot x) = f\left(\sum_{i=1}^d w_i x_i \right)`$ 
    - where 
      - $`w\in\mathbb{R}^d`$ is the vector of weights
      - $`f(\cdot)`$ is an activation function
        - e.g.) Sigmoid 
- Training Process
  - Loss Function : $`\displaystyle\ell(w) = \sum_{\langle x,y \rangle \in S} \left( f(w\cdot x) - y\right)^2`$
    - cf.) Differentiable -> Apply gradient descent to locally minimize the loss (error)
- Multiple Neurons / Layers
  - Multiple neurons.
  - The outputs of each neuron is again fed to new layer of neurons
  - e.g.) Pyramid Like Structure
    - $`w^1 \cdots w^k`$ : $`k`$ neurons where $`o_j = f(w^j x)`$
    - $`y = f(w^{k+1} o)`$ where $`o = [o_1, \cdots, o_k]`$
  - Local Minimization
    - Chain Rule -> Backpropagation
  - Key Idea)
    - Neuronal Selectivity
      - Intermediate neuron can learn new or better or higher level feature that re-represents the features in the previous layer.
- Auto-Encoder
  - Input and Output dimensionality are identical.
  - Smaller layers in the middle.
    - Dimensionality reduction
- RNN



<br><br>

[Back to Main](../main.md)