[Back to Main](../main.md)

# 4. ML Fairness via "Bias Bounties"
- Ideation)
  - Idea 1)
    - Invite the crowd to find "bug" (demographic bias) in a trained ML model.
    - How?)
      - Provide $`\langle x, y, f(x) \rangle`$.
      - Let them find a subgroup that the model $`f`$ underperforms.
    - Limit)
      - Finding an underperformed subgroup does not guarantee that it will improve $`f`$.
      - Hard to evaluate the improvement on the new data.
  - Idea 2)
    - Ask participants to find and submit pairs $`\langle g, h \rangle`$ s.t. $`\widetilde{\epsilon_g}(h) \lneq \widetilde{\epsilon_g}(f)`$ where $`g`$ is a group and $`h`$ is a model.
    - A model $`h`$ that has lower on a specific group $`g`$ compared to the existing $`f`$.
    - Limit)
      - It's hard to derive $`g`$ that specifies the underperformed groups.
    - 

















<br><br>

[Back to Main](../main.md)